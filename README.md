![](https://img.shields.io/github/release/shadowcz007/comfyui-mixlab-nodes)

> é€‚é…äº†æœ€æ–°ç‰ˆ comfyui çš„ py3.11 ï¼Œtorch 2.1.2+cu121
> [Mixlab nodes discord](https://discord.gg/cXs9vZSqeK)

#### `ç›¸å…³æ’ä»¶æ¨è`

<!-- [comfyui-sd-prompt-mixlab](https://github.com/shadowcz007/comfyui-sd-prompt-mixlab) -->

[comfyui-Image-reward](https://github.com/shadowcz007/comfyui-Image-reward)

[comfyui-ultralytics-yolo](https://github.com/shadowcz007/comfyui-ultralytics-yolo)

[comfyui-moondream](https://github.com/shadowcz007/comfyui-moondream)

<!-- [comfyui-CLIPSeg](https://github.com/shadowcz007/comfyui-CLIPSeg) -->

##### `æœ€æ–°`ï¼š

ChatGPT èŠ‚ç‚¹æ”¯æŒ Local LLMï¼ˆllama.cppï¼‰ï¼ŒPhi3ã€llama3 éƒ½å¯ä»¥ç›´æ¥ä¸€ä¸ªèŠ‚ç‚¹è¿è¡Œäº†ã€‚

Model download,move to :`models/llamafile/`

å¼ºçƒˆæ¨èï¼š
[Phi-3-mini-4k-instruct-GGUF](https://huggingface.co/lmstudio-community/Phi-3-mini-4k-instruct-GGUF/tree/main)

[llava-phi-3-mini-gguf](https://huggingface.co/xtuner/llava-phi-3-mini-gguf/tree/main)
æ³¨æ„éœ€è¦æŠŠllava-phi-3-mini-mmproj-f16.ggufä¹Ÿä¸‹è½½


å¤‡é€‰ï¼š
[llama3_if_ai_sdpromptmkr_q2k](https://hf-mirror.com/impactframes/llama3_if_ai_sdpromptmkr_q2k/tree/main)


> å³é”®èœå•æ”¯æŒ text-to-textï¼Œæ–¹ä¾¿å¯¹ prompt è¯è¡¥å…¨
> ![](./assets/prompt_ai_setup.png)
> ![](./assets/prompt-ai.png)

## ğŸš€ğŸš—ğŸššğŸƒ Workflow-to-APP

- æ–°å¢ AppInfo èŠ‚ç‚¹ï¼Œå¯ä»¥é€šè¿‡ç®€å•çš„é…ç½®ï¼ŒæŠŠ workflow è½¬å˜ä¸ºä¸€ä¸ª Web APPã€‚
- æ”¯æŒå¤šä¸ª web app åˆ‡æ¢
- å‘å¸ƒä¸º app çš„ workflowï¼Œå¯ä»¥åœ¨å³é”®é‡Œå†æ¬¡ç¼–è¾‘äº†
- web app å¯ä»¥è®¾ç½®åˆ†ç±»ï¼Œåœ¨ comfyui å³é”®èœå•å¯ä»¥ç¼–è¾‘æ›´æ–° web app
- æ”¯æŒåŠ¨æ€æç¤º

![](./assets/å¾®ä¿¡å›¾ç‰‡_20240421205440.png)

- Support multiple web app switching.
- Add the AppInfo node, which allows you to transform the workflow into a web app by simple configuration.
- The workflow, which is now released as an app, can also be edited again by right-clicking.
- The web app can be configured with categories, and the web app can be edited and updated in the right-click menu of ComfyUI.

![](./assets/0-m-app.png)

![](./assets/appinfo-readme.png)

![](./assets/appinfo-2.png)

Example:

- workflow
  ![APP info](./workflow/appinfo-workflow.svg)
  [text-to-image](./workflow/Text-to-Image-app.json)

APP-JSON:

- [text-to-image](./example/Text-to-Image_3.json)
- [image-to-image](./example/Image-to-Image_2.json)
- text-to-text

> æš‚æ—¶æ”¯æŒ 9 ç§èŠ‚ç‚¹ä½œä¸ºç•Œé¢ä¸Šçš„è¾“å…¥èŠ‚ç‚¹ï¼šLoad Imageã€VHS*LoadVideoã€CLIPTextEncodeã€PromptSlideã€TextInput*ã€Colorã€FloatSliderã€IntNumberã€CheckpointLoaderSimpleã€LoraLoader

> è¾“å‡ºèŠ‚ç‚¹ï¼šPreviewImage ã€SaveImageã€ShowTextForGPTã€VHS_VideoCombineã€PromptImage

> seed ç»Ÿä¸€è¾“å…¥æ§ä»¶ï¼Œæ”¯æŒï¼šSamplerCustomã€KSampler

> é…å¥—[ps æ’ä»¶](https://github.com/shadowcz007/comfyui-ps-plugin)

> å¦‚æœé‡åˆ°ä¸Šä¼ å›¾ç‰‡ä¸æˆåŠŸï¼Œè¯·æ£€æŸ¥ä¸‹ï¼šå±€åŸŸç½‘æˆ–è€…æ˜¯äº‘æœåŠ¡ï¼Œè¯·ä½¿ç”¨ httpsï¼Œç«¯å£ 8189 è¿™ä¸ªæœåŠ¡ï¼ˆ æ„Ÿè°¢ @Damien åé¦ˆé—®é¢˜ï¼‰

> If you encounter difficulties in uploading images, please check the following: for local network or cloud services, please use HTTPS and the service on port 8189. (Thanks to @Damien for reporting the issue.)

## ğŸƒğŸš—ğŸššğŸš€ Real-time Design

> ScreenShareNode & FloatingVideoNode. Now comfyui supports capturing screen pixel streams from any software and can be used for LCM-Lora integration. Let's get started with implementation and design! ğŸ’»ğŸŒ

![screenshare](./assets/screenshare.png)

https://github.com/shadowcz007/comfyui-mixlab-nodes/assets/12645064/e7e77f90-e43e-410a-ab3a-1952b7b4e7da

<!-- [ScreenShareNode](./workflow/2-screeshare.json) -->

[ScreenShareNode & FloatingVideoNode](./workflow/3-FloatVideo-workflow.json)

!! Please use the address with HTTPS (https://127.0.0.1).

### SpeechRecognition & SpeechSynthesis

![f](./assets/audio-workflow.svg)

[Voice + Real-time Face Swap Workflow](./workflow/è¯­éŸ³+å®æ—¶æ¢è„¸workflow.json)

### GPT

> Support for calling multiple GPTs.Local LLMï¼ˆllama.cppï¼‰ã€ ChatGPTã€ChatGLM3 ã€ChatGLM4 , Some code provided by rui. If you are using OpenAI's service, fill in https://api.openai.com/v1 . If you are using a local LLM service, fill in http://127.0.0.1:xxxx/v1 . Azure OpenAI:https://xxxx.openai.azure.com

![gpt-workflow.svg](./assets/gpt-workflow.svg)

[workflow-5](./workflow/5-gpt-workflow.json)

æœ€æ–°ï¼šChatGPT èŠ‚ç‚¹æ”¯æŒ Local LLMï¼ˆllama.cppï¼‰ï¼ŒPhi3ã€llama3 éƒ½å¯ä»¥ç›´æ¥ä¸€ä¸ªèŠ‚ç‚¹è¿è¡Œäº†ã€‚

Model download,move to :`models/llamafile/`

å¼ºçƒˆæ¨èï¼š[Phi-3-mini-4k-instruct-GGUF](https://huggingface.co/lmstudio-community/Phi-3-mini-4k-instruct-GGUF/tree/main)

å¤‡é€‰ï¼š[llama3_if_ai_sdpromptmkr_q2k](https://hf-mirror.com/impactframes/llama3_if_ai_sdpromptmkr_q2k/tree/main)

> å¦‚æœç¢°åˆ°å®‰è£…å¤±è´¥ï¼Œå¯ä»¥å°è¯•æ‰‹åŠ¨å®‰è£…

```
../../../python_embeded/python.exe -s -m pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121

../../../python_embeded/python.exe -s -m pip install llama-cpp-python[server]

```

> [Mac](https://llama-cpp-python.readthedocs.io/en/latest/install/macos/)

```
pip uninstall llama-cpp-python -y
CMAKE_ARGS="-DLLAMA_METAL=on" pip install -U llama-cpp-python --no-cache-dir
pip install 'llama-cpp-python[server]'
```

```
pip install llama-cpp-python \
  --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/metal
```

## Prompt

> PromptSlide
> ![](./assets/prompt_weight.png)

<!-- ![](./workflow/promptslide-appinfo-workflow.svg) -->

> randomPrompt

![randomPrompt](./assets/randomPrompt.png)

> ClipInterrogator

[add clip-interrogator](https://github.com/pharmapsychotic/clip-interrogator)

> PromptImage & PromptSimplification,Assist in simplifying prompt words, comparing images and prompt word nodes.

> ChinesePrompt && PromptGenerateï¼Œä¸­æ–‡ prompt èŠ‚ç‚¹ï¼Œç›´æ¥ç”¨ä¸­æ–‡ä¹¦å†™ä½ çš„ prompt

![](./assets/ChinesePrompt_workflow.svg)

### Layers

> A new layer class node has been added, allowing you to separate the image into layers. After merging the images, you can input the controlnet for further processing.

![layers](./assets/layers-workflow.svg)

![poster](./assets/poster-workflow.svg)

### 3D

![](./assets/3d-workflow.png)
![](./assets/3d_app.png)
[workflow](./assets/Image-to-3D_1.json)

![](./assets/3dimage.png)
[workflow](./workflow/3D-workflow.json)

### Image

#### LoadImagesToBatch

> Upload multiple images for batch input into the IP adapter.

#### LoadImagesFromLocal

> Monitor changes to images in a local folder, and trigger real-time execution of workflows, supporting common image formats, especially PSD format, in conjunction with Photoshop.

![watch](./assets/4-loadfromlocal-watcher-workflow.svg)

[workflow-4](./workflow/4-loadfromlocal-watcher-workflow.json)

#### LoadImagesFromURL

> Conveniently load images from a fixed address on the internet to ensure that default images in the workflow can be executed.

### Style

> Apply VisualStyle Prompting , Modified from [ComfyUI_VisualStylePrompting](https://github.com/ExponentialML/ComfyUI_VisualStylePrompting)

![](./assets/VisualStylePrompting.png)

> StyleAligned , Modified from [style_aligned_comfy](https://github.com/brianfitzgerald/style_aligned_comfy)

### Utils

> The Color node provides a color picker for easy color selection, the Font node offers built-in font selection for use with TextImage to generate text images, and the DynamicDelayByText node allows delayed execution based on the length of the input text.

- [æ·»åŠ äº† DynamicDelayByText åŠŸèƒ½ï¼Œå¯ä»¥æ ¹æ®è¾“å…¥æ–‡æœ¬çš„é•¿åº¦è¿›è¡Œå»¶è¿Ÿæ‰§è¡Œã€‚](./workflow/audio-chatgpt-workflow.json)

- [Added DynamicDelayByText, enabling delayed execution based on input text length.](./workflow/audio-chatgpt-workflow.json)

- [ä½¿ç”¨ CkptNames å¯¹æ¯”ä¸åŒçš„æ¨¡å‹æ•ˆæœ](./workflow/ckpts-image-workflow.json)

- [CkptNames compare the effects of different models.](./workflow/ckpts-image-workflow.json)

### Other Nodes

![main](./assets/all-workflow.svg)
![main2](./assets/detect-face-all.png)

[workflow-1](./workflow/1-workflow.json)

> TransparentImage

![TransparentImage](./assets/TransparentImage.png)

> FeatheredMaskã€SmoothMask

Add edges to an image.

![FeatheredMask](./assets/FlVou_Y6kaGWYoEj1Tn0aTd4AjMI.jpg)

> LaMaInpainting

from [simple-lama-inpainting](https://github.com/enesmsahin/simple-lama-inpainting)

> rembgNode

"briarmbg","u2net","u2netp","u2net_human_seg","u2net_cloth_seg","silueta","isnet-general-use","isnet-anime"

**_ briarmbg _** model was developed by BRlA Al and can be used as an open-source model for non-commercial purposes

### Improvement

- Add "help" option to the context menu for each node.
- Add "Nodes Map" option to the global context menu.

An improvement has been made to directly redirect to GitHub to search for missing nodes when loading the graph.

![help](./assets/help.png)

![node-not-found](./assets/node-not-found.png)

### Models

- [Download TripoSR](https://huggingface.co/stabilityai/TripoSR/blob/main/model.ckpt) and place it in `models/triposr`

- [Download facebook/dino-vitb16](https://huggingface.co/facebook/dino-vitb16/tree/main) and place it in `models/triposr/facebook/dino-vitb16`

[Download rembg Models](https://github.com/danielgatis/rembg/tree/main#Models),move to:`models/rembg`

[Download lama](https://github.com/enesmsahin/simple-lama-inpainting/releases/download/v0.1.0/big-lama.pt), move to : `models/lama`

[Download Salesforce/blip-image-captioning-base](https://huggingface.co/Salesforce/blip-image-captioning-base), move to :`models/clip_interrogator/Salesforce/blip-image-captioning-base`

[Download succinctly/text2image-prompt-generator](https://huggingface.co/succinctly/text2image-prompt-generator/tree/main),move to:`models/prompt_generator/text2image-prompt-generator`

[Download Helsinki-NLP/opus-mt-zh-en](https://huggingface.co/Helsinki-NLP/opus-mt-zh-en/tree/main),move to:`models/prompt_generator/opus-mt-zh-en`

## Installation

manually install, simply clone the repo into the custom_nodes directory with this command:

```
cd ComfyUI/custom_nodes

git clone https://github.com/shadowcz007/comfyui-mixlab-nodes.git

```

Install the requirements:

run directly:

```
cd ComfyUI/custom_nodes/comfyui-mixlab-nodes
install.bat
```

or install the requirements using:

```
../../../python_embeded/python.exe -s -m pip install -r requirements.txt
```

If you are using a venv, make sure you have it activated before installation and use:

```
pip3 install -r requirements.txt
```

#### Chinese community

è®¿é—® [www.mixcomfy.com](https://www.mixcomfy.com)ï¼Œè·å¾—æ›´å¤šå†…æµ‹åŠŸèƒ½ï¼Œå…³æ³¨å¾®ä¿¡å…¬ä¼—å·ï¼šMixlab æ— ç•Œç¤¾åŒº

####

File / LoadImagesFromPath SaveImageToLocal LoadImagesFromURL

#### discussions:

[discussions](https://github.com/shadowcz007/comfyui-mixlab-nodes/discussions)

<picture>
  <source
    media="(prefers-color-scheme: dark)"
    srcset="
      https://api.star-history.com/svg?repos=shadowcz007/comfyui-mixlab-nodes&type=Date&theme=dark
    "
  />
  <source
    media="(prefers-color-scheme: light)"
    srcset="
      https://api.star-history.com/svg?repos=shadowcz007/comfyui-mixlab-nodes&type=Date
    "
  />
  <img
    alt="Star History Chart"
    src="https://api.star-history.com/svg?repos=shadowcz007/comfyui-mixlab-nodes&type=Date"
  />
</picture>
